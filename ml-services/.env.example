# =============================================================================
# ML Microservice Configuration
# =============================================================================
# Copy this file to .env and update with your values
#
# This service connects to:
# - Laravel's PostgreSQL (shared via project2_network)
# - ML-specific databases (MongoDB, Redis, Weaviate, Kafka)

# =============================================================================
# Application Settings
# =============================================================================
APP_NAME=ML Microservice
APP_VERSION=1.0.0
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=true

# =============================================================================
# PostgreSQL Settings (Connects to Laravel's PostgreSQL)
# =============================================================================
# Use 'localhost' when running ML service locally (uvicorn outside Docker)
# Use 'backend_postgres' when running ML service inside Docker
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=backend
POSTGRES_USER=postgres
POSTGRES_PASSWORD=secret
POSTGRES_MIN_POOL_SIZE=5
POSTGRES_MAX_POOL_SIZE=20

# =============================================================================
# MongoDB Settings (ML features and user profiles)
# =============================================================================
MONGO_URI=mongodb://localhost:27017
MONGO_DB=ml_service

# =============================================================================
# Weaviate Settings (Vector embeddings for similarity search)
# =============================================================================
# Port 8085 on host maps to 8080 in container (8080 may conflict with other services)
WEAVIATE_URL=http://localhost:8085
WEAVIATE_API_KEY=
WEAVIATE_GRPC_PORT=50051

# =============================================================================
# Redis Settings (Caching and rate limiting)
# =============================================================================
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=

# =============================================================================
# Kafka Settings (Event streaming with Laravel)
# =============================================================================
# Use 'localhost:29092' when running locally
# Use 'infra-kafka:9092' when running in Docker
KAFKA_BOOTSTRAP_SERVERS=localhost:29092
KAFKA_CONSUMER_GROUP=ml-service

# =============================================================================
# Authentication
# =============================================================================
# Token for service-to-service authentication (Laravel -> ML Service)
SERVICE_AUTH_TOKEN=your_secure_token_here

# =============================================================================
# ML Model Settings
# =============================================================================
# English sentiment model (HuggingFace)
SENTIMENT_MODEL=distilbert-base-uncased-finetuned-sst-2-english

# Arabic sentiment model (HuggingFace)
SENTIMENT_MODEL_ARABIC=CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment

# Sentence transformer for embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# =============================================================================
# Cache TTL Settings (in seconds)
# =============================================================================
CACHE_TTL_PROFILES=3600
CACHE_TTL_RECOMMENDATIONS=300
CACHE_TTL_SENTIMENT=86400

# =============================================================================
# Rate Limiting
# =============================================================================
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# Recommendation Settings
# =============================================================================
RECOMMENDATION_COLLABORATIVE_WEIGHT=0.4
RECOMMENDATION_CONTENT_WEIGHT=0.3
RECOMMENDATION_PERSONALITY_WEIGHT=0.3
RECOMMENDATION_MAX_PER_CATEGORY=3
RECOMMENDATION_DEFAULT_LIMIT=10
